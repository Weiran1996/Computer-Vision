{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision lab7 part B\n",
    "\n",
    "Weiran Wang   ww463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.datasets import get_data_home\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import check_random_state\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.  read the NMIST dataset\n",
    "memory = Memory(get_data_home())\n",
    "@memory.cache()\n",
    "def fetch_mnist():\n",
    "    content = urlopen(\n",
    "        'https://www.openml.org/data/download/52667/mnist_784.arff').read()\n",
    "    data, meta = loadarff(io.StringIO(content.decode('utf8')))\n",
    "    data = data.view([('pixels', '<f8', 784), ('class', '|S1')])\n",
    "    return data['pixels'], data['class']\n",
    "X, y = fetch_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "\n",
    "X = X / 255.\n",
    "y_new = []\n",
    "for i in range(len(y)):\n",
    "    y_new.append(int(y[i]))\n",
    "y = np.asarray(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbor classifier with K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 15.765 seconds\n",
      "Test score with 1NN is: 0.9691\n",
      "Test time 635.881 seconds\n",
      "Test score with 1NN is: 0.9691\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 1NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 1NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbor classifier with K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 16.475 seconds\n",
      "Test score with 3NN is: 0.9705\n",
      "Test time 672.053 seconds\n",
      "Test score with 3NN is: 0.9705\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 3NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 3NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbor classifier with K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 16.735 seconds\n",
      "Test score with 5NN is: 0.9688\n",
      "Test time 666.448 seconds\n",
      "Test score with 5NN is: 0.9688\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As we can see above, although the accuracy of KNN classifier is good, but it;s taking too much time to train and test the dataset, so I choose a portion of them to do the training and testing to save some time. I chose 20000 images used for training and 5000 used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:20000], X[40000:45000] \n",
    "y_train, y_test = y[:20000], y[40000:45000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 1.771 seconds\n",
      "Test score with 5NN is: 0.9586\n",
      "Test time 124.730 seconds\n",
      "Test score with 5NN is: 0.9586\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As we can see above, although the training set and the testing set has been reduced to one third of the oringinal size, but the acuracy is still pretty good, and the trainind and testing time have dropped dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP classifier single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32009978\n",
      "Iteration 2, loss = 0.15347534\n",
      "Iteration 3, loss = 0.11544755\n",
      "Iteration 4, loss = 0.09279764\n",
      "Iteration 5, loss = 0.07889367\n",
      "Iteration 6, loss = 0.07170497\n",
      "Iteration 7, loss = 0.06282111\n",
      "Iteration 8, loss = 0.05530788\n",
      "Iteration 9, loss = 0.04960484\n",
      "Iteration 10, loss = 0.04645355\n",
      "Training time 5.501 seconds\n",
      "Test score with mlp is: 0.9700\n",
      "Test time 0.023 seconds\n",
      "Test score with mlp is: 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#Train the classifier\n",
    "mlp.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp.score(X_test,y_test)\n",
    "print(\"Test score with mlp is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with mlp is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP slassifier single hidden layers with 20 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32009978\n",
      "Iteration 2, loss = 0.15347534\n",
      "Iteration 3, loss = 0.11544755\n",
      "Iteration 4, loss = 0.09279764\n",
      "Iteration 5, loss = 0.07889367\n",
      "Iteration 6, loss = 0.07170497\n",
      "Iteration 7, loss = 0.06282111\n",
      "Iteration 8, loss = 0.05530788\n",
      "Iteration 9, loss = 0.04960484\n",
      "Iteration 10, loss = 0.04645355\n",
      "Iteration 11, loss = 0.04082169\n",
      "Iteration 12, loss = 0.03828222\n",
      "Iteration 13, loss = 0.03557957\n",
      "Iteration 14, loss = 0.03054891\n",
      "Iteration 15, loss = 0.02924761\n",
      "Iteration 16, loss = 0.02610471\n",
      "Iteration 17, loss = 0.02363894\n",
      "Iteration 18, loss = 0.02208186\n",
      "Iteration 19, loss = 0.01932900\n",
      "Iteration 20, loss = 0.01830387\n",
      "Training time 11.079 seconds\n",
      "Test score with mlp is: 0.9723\n",
      "Test time 0.016 seconds\n",
      "Test score with mlp is: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#Train the classifier\n",
    "mlp.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp.score(X_test,y_test)\n",
    "print(\"Test score with mlp is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with mlp is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP slassifier two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.31433496\n",
      "Iteration 2, loss = 0.13096526\n",
      "Iteration 3, loss = 0.09746443\n",
      "Iteration 4, loss = 0.08289663\n",
      "Iteration 5, loss = 0.06756179\n",
      "Iteration 6, loss = 0.06050956\n",
      "Iteration 7, loss = 0.05404734\n",
      "Iteration 8, loss = 0.04829666\n",
      "Iteration 9, loss = 0.04256343\n",
      "Iteration 10, loss = 0.04180814\n",
      "Training time 6.571 seconds\n",
      "Test score with mlp is: 0.9707\n",
      "Test time 0.019 seconds\n",
      "Test score with mlp is: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#Train the classifier\n",
    "mlp_2.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp_2.score(X_test,y_test)\n",
    "print(\"Test score with mlp is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with mlp is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP slassifier two hidden layers with 20 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.31433496\n",
      "Iteration 2, loss = 0.13096526\n",
      "Iteration 3, loss = 0.09746443\n",
      "Iteration 4, loss = 0.08289663\n",
      "Iteration 5, loss = 0.06756179\n",
      "Iteration 6, loss = 0.06050956\n",
      "Iteration 7, loss = 0.05404734\n",
      "Iteration 8, loss = 0.04829666\n",
      "Iteration 9, loss = 0.04256343\n",
      "Iteration 10, loss = 0.04180814\n",
      "Iteration 11, loss = 0.03281876\n",
      "Iteration 12, loss = 0.03400771\n",
      "Iteration 13, loss = 0.03098504\n",
      "Iteration 14, loss = 0.02810166\n",
      "Iteration 15, loss = 0.02454165\n",
      "Iteration 16, loss = 0.02669542\n",
      "Iteration 17, loss = 0.02396344\n",
      "Iteration 18, loss = 0.02521001\n",
      "Iteration 19, loss = 0.02028465\n",
      "Iteration 20, loss = 0.01680745\n",
      "Training time 12.317 seconds\n",
      "Test score with mlp is: 0.9750\n",
      "Test time 0.019 seconds\n",
      "Test score with mlp is: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=20, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#Train the classifier\n",
    "mlp_2.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp_2.score(X_test,y_test)\n",
    "print(\"Test score with mlp is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with mlp is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As we can see, for MLP classifier, two hidden layers gives better accuracy than a single hidden layer, and larger iteration can reduce loss effectively, thus it tends to give better accuracy than smaller iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:30000], X[30000:35000] \n",
    "y_train, y_test = y[:30000], y[30000:35000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine with a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 50.447 seconds\n",
      "Test score with SVM linear kernel is: 0.9184\n",
      "Test time 21.009 seconds\n",
      "Test score with SVM linear kernel is: 0.9184\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "clf = SVC(kernel = 'linear', C = 1)\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with SVM linear kernel is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with SVM linear kernel is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector Machine with a polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 1, 4, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 1442.546 seconds\n",
      "Test score with SVM poly kernel is: 0.3202\n",
      "Test time 132.438 seconds\n",
      "Test score with SVM poly kernel is: 0.3202\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "clf = SVC(kernel = 'poly',degree = 3, C = 1)\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with SVM poly kernel is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with SVM poly kernel is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector Machine with radial basis kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 117.335 seconds\n",
      "Test score with SVM rb kernel is: 0.9234\n",
      "Test time 41.012 seconds\n",
      "Test score with SVM rb kernel is: 0.9234\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "clf = SVC(kernel = 'rbf', C = 1, gamma = 'auto')\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with SVM rb kernel is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with SVM rb kernel is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
